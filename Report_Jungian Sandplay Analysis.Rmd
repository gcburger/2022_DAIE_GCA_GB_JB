--- 
title: "Descriptive & Inferential Analysis of a Jungian Sandplay VR Project"
author: "Gareth Burger &amp; James Bunt"
date: "`r format(Sys.time(), '%a, %d %B %y at %X')`"
always_allow_html: true
output:
  html_document:
    toc: yes
    toc_title: Table Of Contents
    toc_float: yes
    toc_depth: 3
    fig_caption: no
    lof: yes
    number_sections: yes
    code_folding: hide
    theme: paper
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
fontsize: 10pt
subtitle: "Normality testing of patient treatment - Code"
---

```{r setup and library load, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
cat('\014')
```

**WIP**\
*We can rename this README or make the main R Notebook file a completely new file if needed*\
*2-2.5 pages of text needed, not more than 1200 words excluding plots and tables*\

---

# Abstract

## Aim and rationale

Data from a study are presented that investigated the effect of Jungian Sandplay therapy, conducted in a virtual reality environment, on psychotherapy patients undergoing treatment for PTSD.

To test the effectiveness of VR treatment on PTSD, it is reasonable to conclude that the animated VR treatment had a positive effect on PTSD, regardless of gender.

## Participants and setting

The experiment included a random sample of 150 young adult patients aged 18-25 years old with PTSD, evenly split between male and female. From the information provided, therapy was delivered by a therapist and with therapist-led ratings included it can be concluded that the experiment was conducted in a controlled and standardised manner. 

For this analysis, only the difference between the animated VR group and control group were examined with 100 patients in scope.

## Experiment design

It is unclear though whether the experiment was designed to control for potential confounders, and in particular, the fact that PTSD can reduce naturally without intervention (especially over such as long period such as the 12 weeks the experiment ran) and whether the patients benefited from any other support (i.e. it is common for those who have PTSD to take medication, such as anti-depressants which could imapct results).

From a design perspective, the experiment can be deemed as reliable since we have a randomised controlled trial where participants within a pre-determined criteria (young adults aged 18-25 years old) which were sourced using random sampling and randomly assignment to one of three test groups (1 control group and 2 different types of VR).

## Results gathering

Analysis was focused on the difference between the OR (therapist observer rated) pre and post recordings opposed to self observed results due to reliability and bias concerns.

Observer reviewed test results comparing the pre and post PTSD scores after VR treatment yielded a 15.01% improvement compared to the control group's improvement of 11.25% (+3.8%). Whilst all treatment provided an overall improvement, a null hypothesis that VR treatment does not impact PTSD can be rejected and an alternative hypothesis that VR treatment will result in a greater reduction in PTSD compared to traditional pyshchological therapy (control group) is suggested.

## Major findings

It was validated that animated VR therapy yielded the highest improvement to PTSD according to therapist-led OR results by 15.5% compared to control group at 11.25% *include other key stats here*.

## Findings/implications

It is important to keep in mind that the above hypothesis is a prediction and not a definitive statement about the relationship between the VR treatment and reduced PTSD, but rather a starting point for further investigation where more information is needed.

Whilst the data meets the assumptions required for a statistical test *Gareth to explain how we can validate this*, it should also be noted that the experiment information available limits the reliability of findings. Specifically, the age of each participant (i.e. there maybe additional influence of age), the amount of time since diagnosis (since both HSE and Mayo Clinic advise that some PTSD can naturally reduce over time), whether the patient is receiving any potentially conflicting treatment (i.e. PTSD medication) and the time of observation (noting that observations are recorded at the start and end of each day which is not recorded) can impact the results and the reliability of the experiment which can not be validated at this time.

---

# Introduction

## Topic and context

According to the HSE and Mayo Clinic (2022) Post-traumatic stress disorder (PTSD) is a mental health condition that is triggered by a terrifying event â€” either experiencing it or witnessing it. Symptoms may include flashbacks, nightmares and severe anxiety, as well as uncontrollable thoughts about the event (Mayo Clinic, 2022). PTSD symptoms can be physical and/ or emotional and can vary over time or vary from person to person (with or without treatment).

Treatment for PTSD can vary between psychological therapies (such as cognitive behavioural therapy - CBT) and medication (such as antidepressants). This study will only focus on the difference between traditional pyschological therapy (CBT) and new VR versions (animated) of a Jungian Sandplay  (a therapeutic method that uses sand, miniature objects, and image making within the context of the psychology of Carl Jung (Dooley, 2018).

## Rationale

There are several methods employed to assess patient PTSD including observer-rated (OR), self- reported (CPSS), parental reported, and physiological measurements however only OR pre and post scores are used in this analysis due to reliability concerns of self recorded data outside a controlled and standardised manner which is essential for a robust experiment. Also note that specific focus will be applied on the variance between the pre and post scores (impact).

To focus analysis, two test groups were compared, specifically the animated VR therapy group of 50 patients against the control group of 50 patients who received traditional cognitive behavioural therapy.

## Hypothesis

A null hypothesis is that Animated VR therapy does not have a greater effect on PTSD than the control group (traditional CBT therapy) with an alternative hypothesis that both animated VR therapy has a greater, positive effect on PTSD in young adult patients.

Note that there is no confirmation that participants are not receiving any additional treatment which can easily impact the experiment results therefore the hypothesis can not be validated

# Method

It is unclear though whether the experiment was designed to control for potential confounders, and in particular, the fact that PTSD can reduce naturally without intervention (especially over such as long period such as the 12 weeks the experiment ran) and whether the patients benefited from any other support (i.e. it is common for those who have PTSD to take medication, such as anti-depressants which could impact results).

From a design perspective, the experiment can be deemed as reliable since we have a randomised controlled trial where participants within a pre-determined criteria (young adults aged 18-25 years old) which were sourced using random sampling and randomly assignment to one of three test groups (1 control group and 2 different types of VR).

## Participants

The experiment included a random sample of 150 young adult patients aged 18-25 years old with PTSD, evenly split between male and female. Note that it is unclear according to the information provided why young adults were specifically selected in this experiment however research does indicate that PTSD does impact young adult males (aged 18-24 years old) the most so this audience does represent the highest impacted population. 

During that time the patients either underwent traditional CBT or the new VR therapy, it is clear that the delivery of the VR experience was consistent through 12 weeks of 50 minutes treatment per week with a therapist therefore it is adequately assumed that delivery was consistent and controlled.

## Design

There are a few important factors that should be considered when conducting this experiment which has not been explicitly mentioned so must be considered and noted as it impacts the reliability of analysis and results.

Firstly, it is important to ensure that the study is conducted in a controlled and standardised manner. This means that the sample of patients should be selected using a random sampling method, and the groups should be of equal size to avoid any potential bias. From the information provided, since an appropriate random sampling approach has been followed, this is deemed to be appropriate and reliable however it should be noted that we have no information regarding other treatment which the patients could be involved with (since all patients have diagnosed PTSD, treatment is likely) which can directly impact the reliability of these results.

Second, studies like this should be designed to control for potential confounders, such as the patient's age, gender, and any other factors that could affect the outcome of the experiment. Gender and age is controlled within sampling which is sufficient however additional information on potentially conflicting treatment (i.e. mediciation) is not mentioned. Within the data, whilst gender is recorded, information on specific age and time of observation (i.e. start of end of day) which can impact results. 

Third, it is important that this study should use valid and reliable measures to assess the patients' PTSD levels, both at the start and end of the study therefore all self recorded (CPSS) results have been discounted since they are self reported and uncontrolled. Focusing analysis on the observer rated results (OR) will help ensure that the results of the study are accurate and unbiased so they can be compared across the different test groups.

Fourth, it should be noted that it is important to ensure that the therapists administering the treatment are trained and experienced in using the VR app, as well as in providing traditional CBT which has not been validated within the information provided. It is assumed that all patients are receiving high-quality, consistent treatment so that any differences in outcomes between the groups can be attributed to the difference in treatment type.

Finally, the study should include a sufficient number of patients to provide statistical power and to ensure that the results are statistically significant. It has been deemed that the 150 patient population (50 per treatment type) is sufficient for this analysis and will help ensure that any observed differences between the groups can be confidently attributed to the VR app rather than to chance.

## Materials

Based on the information provided, we know that all test groups underwent 12 weeks of treatment for 50 minutes per week with a therapist with the VR test group receiving a 'quality' version of the VR app. No other information is available about the material used for therapy or results gathering other than that a standardised scale was used with a range of 0 to 10.

## Procedure

Before being able to perform calculations and carry out statistical tests on our data, we need to load, inspect, clean, filter and group it.

### Load Data
```{r Load Data, echo=TRUE}
# load data from csv
file_name = "./data/daie_ca3_data_13.csv"
study_data <- read.csv(file_name)
```

### Inspect Data Structure
```{r Inspect Head, Tail & Structure, echo=TRUE}
# show data structure
#str(study_data)

# show first 10 rows
#head(study_data, 10)

# show last 10 rows
#tail(study_data, 10)

# show a table containing all the data
knitr::kable(study_data, 
             align = c('c'), 
             digits = 2, 
             caption="Study Data")
```

### Data Cleaning and Filtering
There are three instances of error in the data:

- Row 14: post_trial_cpss has a value of 12 (test_group = Static)
- Row 42: test_group is missing value 'Static'
- Row 64: gender has a value of 'mal'

Our hypothesis is looking at the difference between pre_trial_or and post_trial_or scores for the Control and Animated groups only, not testing gender as a contributing factor, so as it turned out we can safely ignore the errors in the data as they do not form part of the filtered subset we are investigating.

```{r}
#install.packages("tidyverse")
#install.packages("dplyr")
#install.packages("knitr")

# load and attach packages
library(tidyverse)
library(dplyr)
library(knitr)

#View(study_data)
#glimpse(study_data)
```

#### Filtered Subset
```{r}
# select filtered data required for hypothesis testing
study_data_filtered <- study_data %>%
  select(test_group, ends_with("or")) %>%
  filter(test_group %in% c("Control", "Animated") 
         & pre_trial_or > 0, pre_trial_or < 10
         & post_trial_or > 0, post_trial_or < 10) %>%
  mutate(trial_or_diff = post_trial_or - pre_trial_or)

# check for duplicates
study_data_filtered %>% distinct() # 100 rows returned, so no duplicates
duplicated(study_data_filtered) # all logical vector values are FALSE i.e. no duplicates

# group count check - Control and Animated both have 50 rows so no missing rows
study_data_filtered %>% count(test_group)

# check for missing score data
# all means are able to be calculated, thus there's no missing numeric data in those columns
mean(study_data_filtered$pre_trial_or) # 5.9741
mean(study_data_filtered$post_trial_or) # 5.3965
mean(study_data_filtered$trial_or_diff) # -0.5776

# extra check for completeness of rows: 0 incomplete rows in subset
study_data_filtered  %>%
  filter(!complete.cases(.))

# create subsets to separate test groups
subset_control <- study_data_filtered %>%
  filter(test_group == "Control")

subset_animated <- study_data_filtered %>%
  filter(test_group == "Animated")

# manually view and verify filtered data subset
#View(study_data_filtered)
#View(subset_control)
#View(subset_animated)

knitr::kable(study_data_filtered, 
             align = c('c'), 
             digits = 2, 
             caption = "Filtered Data required for Hypothesis Testing")

knitr::kable(subset_control, 
             align = c('c'), 
             digits = 2, 
             caption="Control Group Subset")

knitr::kable(subset_animated, 
             align = c('c'), 
             digits = 2, 
             caption = "Animated Group Subset")
```

---

# Results

---

## Descriptive statistics

### Mean and Standard Deviation
```{r}
mean_control_or_diff <- mean(subset_control$trial_or_diff)
std_control_or_diff <- sd(subset_control$trial_or_diff)

mean_animated_or_diff <- mean(subset_animated$trial_or_diff)
std_animated_or_diff <- sd(subset_animated$trial_or_diff)
```

The means and standard deviations of the difference between the pre and post trial observer rated scores for the control and animated groups are shown below:

control_or_diff: M = `r round(mean_control_or_diff, 2)`, SD = `r round(std_control_or_diff, 2)`

animated_or_diff: M = `r round(mean_animated_or_diff, 2)`, SD = `r round(std_animated_or_diff, 2)`

### Data Summary
A summary of the data is shown below:

```{r Summary, echo=TRUE}
summary(subset_control)
boxplot(subset_control$trial_or_diff, 
        ylab = "Score", 
        main = "Control Group OR Difference")

summary(subset_animated)
boxplot(subset_animated$trial_or_diff, 
        ylab = "Score", 
        main = "Animated Group OR Difference")
```

---

## Inferential statistics
The inference and statistical tests that we are doing on our data make the assumption that the data are normally distributed. Thus the below tests are first carried out to check this assumption by testing for normality.

### Testing for Normality

#### Method 1: Using Histogram / Density Plot
```{r Histograms, echo=TRUE}
# draw histogram for control_or_diff
hist(subset_control$trial_or_diff, 
     main = "Control Group OR Difference", 
     xlab = "Score", 
     ylab = "Frequency", 
     breaks = 6, 
     col = 'steelblue')

# draw histogram for animated_or_diff
hist(subset_animated$trial_or_diff, 
     main = "Animated Group OR Difference", 
     xlab = "Score", 
     ylab = "Frequency", 
     breaks = 6, 
     col = 'steelblue')
```

Both histograms above exhibit data that could be normally distributed as they are both roughly "bell-shaped" in nature, though the 'Animated Group OR Difference' histogram is slightly right skewed which indicates a few higher scoring outliers.

---

#### Method 2: Using Q-Q Plot

```{r QQ Plots, echo=TRUE}
# perform qqnorm test on control_or_diff
qqnorm(subset_control$trial_or_diff, 
       pch = 2, 
       frame = FALSE, 
       main = "Control Group OR Difference")
qqline(subset_control$trial_or_diff, 
       col = "darkorchid", 
       lwd = 1)

# perform qqnorm test on animated_or_diff
qqnorm(subset_animated$trial_or_diff, 
       pch = 2, 
       frame = FALSE, 
       main = "Animated Group OR Difference")
qqline(subset_animated$trial_or_diff, 
       col = "darkorchid", 
       lwd = 1)
```

In both Q-Q plots above, the majority of the sample points roughly fall along the diagonal Q-Q line and thus give an indication that the data is normally distributed. However, as not all points fall exactly on the line we will continue testing to investigate further. Again we can see the high outliers in the 'Animated Group OR Difference' plot, with most points falling on the Q-Q line.

---

#### Method 3: Statistical Test: Shapiro-Wilk
The threshold for normality is 0.05 (5%). If the p-value is above the threshold then we can accept the data to be normally distributed.\

```{r Shapiro-Wilk - control_or_diff, echo=TRUE}
# perform shapiro-wilk test on control_or_diff
control_or_diff_sw <- shapiro.test(subset_control$trial_or_diff)
control_or_diff_sw
```
A `r control_or_diff_sw$method` was conducted on the trial_or_diff data of the Control group.\
From the output obtained we can assume normality as the p-value (p = `r round(control_or_diff_sw$p.value, 4)`) is greater than 0.05.

```{r Shapiro-Wilk - animated_or_diff, echo=TRUE}
# perform shapiro-wilk test on animated_or_diff
animated_or_diff_sw <- shapiro.test(subset_animated$trial_or_diff)
animated_or_diff_sw
```
A `r animated_or_diff_sw$method` was conducted on the trial_or_diff data of the Animated group.\
From the output obtained we cannot assume normality as the p-value (p = `r round(animated_or_diff_sw$p.value, 4)`) is less than 0.05.

However, a Shapiro-Wilk in isolation does not guarantee normality or non-normality of data. Interestingly, when you look at the raw source sample data of the pre and post scores for the animated group (and not only the calculated difference between the two), both display Shapiro-Wilk results that indicate normality.

```{r Shapiro-Wilk - animated_pre_trial_or, echo=TRUE}
# perform shapiro-wilk test on animated_pre_trial_or
animated_pre_trial_or_sw <- shapiro.test(subset_animated$pre_trial_or)
animated_pre_trial_or_sw
```

```{r Shapiro-Wilk - animated_post_trial_or, echo=TRUE}
# perform shapiro-wilk test on animated_post_trial_or
animated_post_trial_or_sw <- shapiro.test(subset_animated$post_trial_or)
animated_post_trial_or_sw
```
Animated group: pre_trial_or p-value (p = `r round(animated_pre_trial_or_sw$p.value, 4)`) is greater than 0.05.\
Animated group: post_trial_or p-value (p = `r round(animated_post_trial_or_sw$p.value, 4)`) is greater than 0.05.

Looking at these results alongside the histogram and Q-Q plots, it is reasonable to say that the trial_or_diff data of the Animated group may be slightly non-normal with some positive skew on the right tail, but also that it is normal enough to be able to perform statistical t-tests.

---

## Statistical tests
```{r}
# perform t-test
t.test(data = study_data_filtered, trial_or_diff ~ test_group, mu=0, alt="two.sided", conf=0.95)
```

```{r}
# perform t-test
t.test(subset_control$trial_or_diff, mu=0, alt="two.sided", conf=0.95)
```
```{r}
# perform t-test
t.test(subset_animated$trial_or_diff, mu=0, alt="two.sided", conf=0.95)
```

If there isn't actually a difference between the mean scores of the Control and Animated groups, if the difference is in fact zero (null hypothesis)
Then what are the changes that from our sample we would get the difference that we observed - the probability of that happening is the p-value
very low p value, reject the null hypothesis - the assumption that the difference between the means is zero




*6. Determine the 95% confidence interval for the population mean of each group, and the 95% confidence interval for the difference between the means of any two groups for a variable of your choice.*\

We are 95% confident that [PE + x, PE - x] of all animated group patients, PTSD therapy helped them

p-value and t test
when p-value is below 0.05 - what you're saying is: I got a sample mean before of x, I got a sample mean of afterwards of x+2
difference is 2 (2/10 e.g.)
p-value below 0.05 means there's only a 5% that the null hypothesis can still be true given that you see these results
5% probability that the null hypothesis is true given that we are seeing the difference in values (of means)
if p-value is so low, and you're seeing the difference in values, that's encouraging you to reject the null hypothesis - i.e. < 5% is the probability that the differences in means exist and that the null hypothesis is true
therefore p-value of < 0.05 means reject the null hypothesis i.e something is indeed happening


If the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, we must stick with the null hypothesis. i.e. if p-value is >= 0.05, null hypothesis is true

---

## Magnitude and direction of results
**list results**

---

# Discussion

---

*5. Analyse the data to provide the hypothesis testing conclusion.*\

## Outline findings and relation to the hypothesis
*then lastly, is there a correlation between something that we put in and something that we get out, are there correlations between 2 variables*


81% of patients experienced improvement in their PTSD symptoms after VR treatment and overall, all test groups experienced an improvement of 13.3% median improvement (-0.72 points between pre and post ratings) which supports the alternative hypothesis that both animated VR therapy reduces PTSD.

VR groups reduced PTSD scores by 15.01%, this equals to 3.8% more than the control group (-0.8 compared to -0.54) which means that we can also reject the null hypothesis.

VR impact median reduced by 15.01%. Pre score median was 6.16 with a range of 2.06. Post score median was 5.43 with a range of 5.22.

No notable difference between VR groups was experienced (animated) with a 0.49% variance in impact (between pre and post scores)

Control impact median reduced by -11.25%. Pre score median was 5.98 with a range of 4.75. Post score median was 5.31 with a range of 5.44

No notable difference between gender for those groups recieving VR Therapy (0.08 or 0.49% range in impact) however note that females were also receptive to the control experience (-12.5% impact in control compared to -15.0% in VR)

Note that 70% of the 10 participants who experienced the most impact, were males from the static VR group.

Cleaning of the data was required, specifically; 1 row had to be removed due to a missing test group, 1 row had a mispelt gender which was corrected and 1 row had a CPSS post result of 12 (2 over the maximum scale) however this row was kept in the set as only the OR data was considered in this analysis.

*Gareth - Is the data appropriate for the tests available? (is 50 big enough for each test group?)*

2. Formulate a single hypothesis test to be used to compare the effectiveness of the approaches used during the experiment.

3. Determine if the data meet the assumptions required by any statistical test.

4. Provide descriptive statistics (graphs and tables) for any assumptions made.

5. Analyse the data to provide the hypothesis testing conclusion.

6. Determine the 95% confidence interval for the population mean of each group, and
the 95% confidence interval for the difference between the means of any two groups
for a variable of your choice.

7. Determine the degree of correlation between any explanatory and response variable
of your choice.







## Limitations (if confounding variables are clearly identified by your group)

We're not aware of any confounding variables in the data provided, however there could be limitations to the study to consider including natural improvements to PTSD without treatment and the impact of other PTSD treatments on the patients being assessed (i.e. medication).

---

# References

---

- Bhalla, D. (2016) 'DPLYR Tutorial: Data Manipulation (50 Examples)'. Available at: https://www.listendata.com/2016/08/dplyr-tutorial.html. Accessed on 18 December 2022.

- Ã‡etinkaya-Rundel, M. (2018) '5 1A t distribution'. Available at: https://www.youtube.com/watch?v=uVEj2uBJfq0&list=PLkIselvEzpM5G3IO1tzQ-DUThsJKQzQCD&ab_channel=Mine%C3%87etinkaya-Rundel. Accessed on 22 December 2022.

- Ã‡etinkaya-Rundel, M. (2018) '5 1B Inference for a mean'. Available at: https://www.youtube.com/watch?v=RYVIGj1l4xs&list=PLkIselvEzpM5G3IO1tzQ-DUThsJKQzQCD&ab_channel=Mine%C3%87etinkaya-Rundel. Accessed on 22 December 2022.

- Ã‡etinkaya-Rundel, M. (2018) '5 2 Inference for paired data'. Available at: https://www.youtube.com/watch?v=K0QZ9_4w0HU&list=PLkIselvEzpM5G3IO1tzQ-DUThsJKQzQCD&ab_channel=Mine%C3%87etinkaya-Rundel. Accessed on 22 December 2022.

- Ã‡etinkaya-Rundel, M. (2018) '5 3 Difference of two independent means'. Available at: https://www.youtube.com/watch?v=emZ24asR2F4&list=PLkIselvEzpM5G3IO1tzQ-DUThsJKQzQCD&ab_channel=Mine%C3%87etinkaya-Rundel. Accessed on 22 December 2022.

- Dooley, M. (2018) 'Jungian Sandplay'. Available at: https://maevedooley.ie/sandplay/. Accessed on 20 December 2022.

- Field, A. (2016) 'Writing a Laboratory Report original (2016)'. Available at: https://www.discoveringstatistics.com/docs/writinglabreports.pdf. Accessed on 24 December 2022.

- HSE (2022). 'Post-traumatic stress disorder (PTSD)'. Available at: https://www2.hse.ie/conditions/ptsd/treatment/. Accessed on 21 December 2022.

- Mayo Clinic (2022). 'Post-traumatic stress disorder (PTSD)'. Available at: https://www.mayoclinic.org/diseases-conditions/post-traumatic-stress-disorder/symptoms-causes/syc-20355967. Accessed on 21 December 2022.

- OpenIntroOrg (2019) 'Intro to Confidence Intervals via Proportions'. Available at: https://www.youtube.com/watch?v=A6_W8qY8zJo&list=PLkIselvEzpM4SHQojH116fYAQJLaN_4Xo&ab_channel=OpenIntroOrg. Accessed on 21 December 2022.

- OpenIntroOrg (2015) 'Hypothesis Testing Fundamentals'. Available at: https://www.youtube.com/watch?v=NVbPE1_Cbx8&list=PLkIselvEzpM4SHQojH116fYAQJLaN_4Xo&ab_channel=OpenIntroOrg. Accessed on 21 December 2022.

- OpenIntroOrg (2014) 'Inference for Estimators Other Than the Mean'. Available at: https://www.youtube.com/watch?v=PUMBNtVKr_g&list=PLkIselvEzpM4SHQojH116fYAQJLaN_4Xo&ab_channel=OpenIntroOrg. Accessed on 21 December 2022.

- R Programming 101 (2021) 'Clean your data with R. R programming for beginners'. Available at: https://www.youtube.com/watch?v=sV5lwAJ7vnQ&t=2s&ab_channel=RProgramming101. Accessed on 18 December 2022.

- Tyagi, N. (2022) '7 Types of Statistical Analysis: Definition and Explanation'. Available at: https://www.analyticssteps.com/blogs/7-types-statistical-analysis-definition-explanation. Accessed on 19 December 2022.

- Zach (2021) 'How to Test for Normality in R (4 Methods)'. Available at: https://www.statology.org/test-for-normality-in-r/. Accessed on 18 December 2022.
