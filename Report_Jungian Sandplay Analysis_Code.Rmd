--- 
title: "Descriptive & Inferential Analysis of a Jungian Sandplay VR Project"
author: "Gareth Burger &amp; James Bunt"
date: "`r format(Sys.time(), '%a, %d %B %y at %X')`"
always_allow_html: true
output:
  html_document:
    toc: yes
    toc_title: Table Of Contents
    toc_float: yes
    toc_depth: 3
    fig_caption: no
    lof: yes
    number_sections: yes
    code_folding: hide
    theme: paper
  pdf_document:
    toc: true
    toc_depth: '3'
fontsize: 10pt
subtitle: "Normality testing of patient treatment - Code"
---

```{r setup and library load, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
cat('\014')
```

**WIP**\
*We can rename this README or make the main R Notebook file a completely new file if needed*\
*2-2.5 pages of text needed, not more than 1200 words excluding plots and tables*\

---

# Abstract

---

*NB to be succinct and clear here*

## Aim and rationale

## Participants and setting

## Experiment design

## Results gathering

## Major findings

## Findings/implications

---

# Introduction

---

## Topic and context

## Rationale

*2. Formulate a single hypothesis test to be used to compare the effectiveness of the approaches used during the experiment.*\

## Hypothesis
**Null hypothesis: therapy makes no difference, no matter the patient group (i.e. no difference between the pre and post_trial_or (oberserver-rated, therapist) scores for Animated and Control groups**

**Our Alternative hypothesis: The effect of animated VR therapy is more positive/sees better results than the effect of standard (no VR) therapy (i.e. the difference between pre and post_trial_or scores for the animated group is higher than that of the control group**

**could state that we are focusing on or scores and not observer rated scores with the assumption that they would be more accurate, or something like that**


We always have the null and the alternate hypothesis.
The null says no, the experiment didn't make any difference.
Give them animated models - didn't make any difference.
Male or Female, didn't make any difference.
Null = no effect

Alternate - something has happened here that is statistically significant
Though the probability of seeing a difference between pre and post is actually very low
p-value and t test
when p-value is below 0.05 - what you're saying is: I got a sample mean before of x, I got a sample mean of afterwards of x+2
difference is 2 (2/10 e.g.)
p-value below 0.05 means there's only a 5% that the null hypothesis can still be true given that you see these results
5% probability that the null hypothesis is true given that we are seeing the difference in values (of means)
if p-value is so low, and you're seeing the difference in values, and the null hypothesis is true, that's encouraging you to reject the null hypothesis - i.e. < 5% is the probability that the differences in means exist and that the null hypothesis is true
therefore p-value of <0.05 means reject the null hypothesis i.e something is indeed happening

For the CA we have to state what we think is the null (no effect) hypothesis and what the alternate hypothesis is

If it is quite unlikely to obtain results as in the actual data, we should decide to reject the null hypothesis in favour of the alternative

1. start with a null hypothesis (H0) (that represents no effect/the status quo)
2. state the alternative hypothesis (Ha) (the represents our research question)
3. Conduct a hypothesis test under the assumption that the null hypothesis is true, using p-value test which tells us the probability that this has occurred by accident is very low is p-value is < 0.05 i.e. reject null hypothesis - alternative hypothesis is true
so again p-value <0.05 means that there's only a 5% chance that we would be observing the difference between before and after means if the null hypothesis was true. So because the probability is really low, we have to reject the null hypothesis meaning its not true

If the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, we must stick with the null hypothesis. i.e. if p-value is >= 0.05, null hypothesis is true

- one null and one alternative hypothesis
- descriptive statistics - plots
- test for normality
- an abstract
- some conclusions, based on p-value reject or accepting null hypothesis

e.g.
mean before is 0.6
mean after is 0.7
the difference between the two means should not be zero, therefore there must be some effect
so that could be our alternate hypothesis
null is that no effect happened

only use student t test

---

# Method

---

## Participants

## Design

## Materials

## Procedure

---

# Results

---

## Descriptive statistics

### Load Data
```{r Load Data, echo=TRUE}
# where code is commented out, it's because we don't want it displaying in the final report

# load data from csv
file_name = "./data/daie_ca3_data_13.csv"
study_data <- read.csv(file_name)
```

### Inspect Data Structure
```{r Inspect Head, Tail & Structure, echo=TRUE}
# show data structure
#str(study_data)

# show first 10 rows
#head(study_data, 10)

# show last 10 rows
#tail(study_data, 10)

# show a paged table containing all the data
rmarkdown::paged_table(study_data)
```

### Data Cleaning and Filtering
There are three instances of error in the data:

- Row 14: post_trial_cpss has a value of 12 (test_group = Static)
- Row 42: test_group is missing value 'Static'
- Row 64: gender has a value of 'mal'

Our hypothesis is looking at the difference between pre_trial_or and post_trial_or scores for the Control and Animated groups only, not testing gender as a contributing factor, so as it turned out we can safely ignore the errors in the data as they do not form part of the filtered subset we are investigating.

```{r}
# install.packages("tidyverse")
# install.packages("dplyr")

# load and attach tidyverse and dplyr packages
library(tidyverse)
library(dplyr)

View(study_data)

# variable types
#glimpse(study_data)
```

#### Filtered Subset
```{r}
# select filtered data required for hypothesis testing
study_data_filtered <- study_data %>%
  select(test_group, ends_with("or")) %>%
  filter(test_group %in% c("Control", "Animated") 
         & pre_trial_or > 0, pre_trial_or < 10
         & post_trial_or > 0, post_trial_or < 10) %>%
  mutate(trial_or_diff = post_trial_or - pre_trial_or)

subset_control <- study_data_filtered %>%
  filter(test_group == "Control")

subset_animated <- study_data_filtered %>%
  filter(test_group == "Animated")

# check for duplicates
study_data_filtered %>% distinct() # 100 rows returned, so no duplicates
duplicated(study_data_filtered) # all logical vector values are FALSE i.e. no duplicates

# group count check - Control and Animated both have 50 rows so no missing rows
study_data_filtered %>% count(test_group)

# check for missing score data
# all means are able to be calculated, thus there's no missing numeric data in those columns
mean(study_data_filtered$pre_trial_or) # 5.9741
mean(study_data_filtered$post_trial_or) # 5.3965

# extra check for completeness of rows: 0 incomplete rows in subset
study_data_filtered  %>%
  filter(!complete.cases(.))

# manually view and verify filtered data subset
View(study_data_filtered)
View(subset_control)
View(subset_animated)
```

### Mean and Standard Deviation
```{r Mean & Median, echo=TRUE}
pre_trial_or_mean <- mean(study_data_filtered$pre_trial_or)
pre_trial_or_std <- sd(study_data_filtered$pre_trial_or)

post_trial_or_mean <- mean(study_data_filtered$post_trial_or)
post_trial_or_std <- sd(study_data_filtered$post_trial_or)
```
pre_trial_or: M = `r round(pre_trial_or_mean, 2)`, SD = `r round(pre_trial_or_std, 2)`

post_trial_or: M = `r round(post_trial_or_mean, 2)`, SD = `r round(post_trial_or_std, 2)`

```{r}
mean_control_or_diff <- mean(subset_control$trial_or_diff)
std_control_or_diff <- sd(subset_control$trial_or_diff)

mean_animated_diff <- mean(subset_animated$trial_or_diff)
std_animated_or_diff <- sd(subset_animated$trial_or_diff)
```
control_or_diff: M = `r round(mean_control_or_diff, 2)`, SD = `r round(std_control_or_diff, 2)`

animated_or_diff: M = `r round(mean_animated_diff, 2)`, SD = `r round(std_animated_or_diff, 2)`

### Data Summary
A summary of the data is shown below:

```{r Summary, echo=TRUE}
summary(subset_control)
boxplot(subset_control$trial_or_diff, xlab="", ylab = "Score", main = "Control Group OR Difference")

summary(subset_animated)
boxplot(subset_animated$trial_or_diff, xlab="", ylab = "Score", main = "Animated Group OR Difference")
```

---

## Inferential statistics
The inference and statistical tests that we are doing on our data make the assumption that the data are normally distributed. Thus the below tests are first carried out to check this assumption by testing for normality.

### Testing for Normality

#### Method 1: Using Histogram / Density Plot
```{r Histograms, echo=TRUE}
# draw histogram for pre_trial_or
hist(study_data_filtered$pre_trial_or, main="Pre Trial Observer Rated", xlab="Measured Score", ylab="Frequency", breaks=6, col='steelblue')

# draw histogram for post_trial_or
hist(study_data_filtered$post_trial_or, main="Post Trial Observer Rated", xlab="Measured Score", ylab="Frequency", breaks=6, col='steelblue')

# draw histogram for control_or_diff
hist(subset_control$trial_or_diff, main="Control Group OR Difference", xlab="Score", ylab="Frequency", breaks=6, col='steelblue')

# draw histogram for animated_or_diff
hist(subset_animated$trial_or_diff, main="Animated Group OR Difference", xlab="Score", ylab="Frequency", breaks=6, col='steelblue')
```

Both histograms above exhibit data that is normally distributed as they are both roughly "bell-shaped" in nature.

---

#### Method 2: Using Q-Q Plot

```{r QQ Plots, echo=TRUE}
# perform qqnorm test on pre_trial_or
qqnorm(study_data_filtered$pre_trial_or, pch=2, frame=FALSE, main="Pre Trial Observer Rated")
qqline(study_data_filtered$pre_trial_or, col="darkorchid", lwd=1)

# perform qqnorm test on post_trial_or
qqnorm(study_data_filtered$post_trial_or, pch=2, frame=FALSE, main="Post Trial Observer Rated")
qqline(study_data_filtered$post_trial_or, col="darkorchid", lwd=1)

# perform qqnorm test on control_or_diff
qqnorm(subset_control$trial_or_diff, pch=2, frame=FALSE, main="Control Group OR Difference")
qqline(subset_control$trial_or_diff, col="darkorchid", lwd=1)

# perform qqnorm test on animated_or_diff
qqnorm(subset_animated$trial_or_diff, pch=2, frame=FALSE, main="Animated Group OR Difference")
qqline(subset_animated$trial_or_diff, col="darkorchid", lwd=1)
```

In both Q-Q plots above, the sample points roughly fall along the diagonal Q-Q line and thus give a good indication that the data is normally distributed. However, as not all points fall exactly on the line we will continue testing to investigate further.

---

#### Method 3: Statistical Test: Shapiro-Wilk
The threshold for normality is 0.05 (5%). If the p-value is above the threshold then we can accept the data to be normally distributed.\

```{r Shapiro-Wilk - pre_trial_or, echo=TRUE}
# perform shapiro-wilk test on pre_trial_or
pre_trial_or_sw <- shapiro.test(study_data_filtered$pre_trial_or)
pre_trial_or_sw
```
A `r pre_trial_or_sw$method` was conducted on the pre_trial_or data.\
From the output obtained we can assume normality as the p-value (p = `r round(pre_trial_or_sw$p.value, 4)`) is greater than 0.05.

```{r Shapiro-Wilk - post_trial_or, echo=TRUE}
# perform shapiro-wilk test on post_trial_or
post_trial_or_sw <- shapiro.test(study_data_filtered$post_trial_or)
post_trial_or_sw
```
A `r post_trial_or_sw$method` was conducted on the post_trial_or data.\
From the output obtained we can assume normality as the p-value (p = `r round(post_trial_or_sw$p.value, 4)`) is greater than 0.05.

```{r Shapiro-Wilk - control_or_diff, echo=TRUE}
# perform shapiro-wilk test on control_or_diff
control_or_diff_sw <- shapiro.test(subset_control$trial_or_diff)
control_or_diff_sw
```
A `r control_or_diff_sw$method` was conducted on the trial_or_diff data of the Control group.\
From the output obtained we can assume normality as the p-value (p = `r round(control_or_diff_sw$p.value, 4)`) is greater than 0.05.

```{r Shapiro-Wilk - animated_or_diff, echo=TRUE}
# perform shapiro-wilk test on animated_or_diff
animated_or_diff_sw <- shapiro.test(subset_animated$trial_or_diff)
animated_or_diff_sw
```
A `r animated_or_diff_sw$method` was conducted on the trial_or_diff data of the Animated group.\
From the output obtained we can assume normality as the p-value (p = `r round(animated_or_diff_sw$p.value, 4)`) is greater than 0.05.

As neither p-value is close to the threshold for normality, it is not necessary to test for normality via the fourth method of performing a Kolmogorov-Smirnov test.\

---

## Statistical tests
**t test here**
```{r}
mean(study_data_filtered$pre_trial_or) # 5.9741
sd(study_data_filtered$pre_trial_or) # 1.042748

mean(study_data_filtered$post_trial_or) # 5.3965
sd(study_data_filtered$post_trial_or) # 1.119804

n = 50

pre_trial_or_mean <- mean(study_data_filtered$pre_trial_or)
pre_trial_or_std <- sd(study_data_filtered$pre_trial_or)

post_trial_or_mean <- mean(study_data_filtered$post_trial_or)
post_trial_or_std <- sd(study_data_filtered$post_trial_or)

```





*6. Determine the 95% confidence interval for the population mean of each group, and the 95% confidence interval for the difference between the means of any two groups for a variable of your choice.*\

95% confidence interval = point estimate +- 1.96 * standard error
x bar (mean) +- 1.96 * standard error

mean = p

SE = sqrt( p(1-p)/n )  - slides 19-20 of chapter 5

or

SE = SD / sqrt(n)

p = point estimate +/- 1.96 * SE
  = PE +/- ***
We are 95% confident that [PE + x, PE - x] of all animated group patients, PTSD therapy helped them

```{r}
qt(0.025, df = 49) # t*49 = 2.01

# mean +- t * SD/sqrt(n)
# mean +- 2.01 * (SD/sqrt(50))
```


*7. Determine the degree of correlation between any explanatory and response variable of your choice.*\

---

## Magnitude and direction of results

---

# Discussion

---

*5. Analyse the data to provide the hypothesis testing conclusion.*\

## Outline findings and relation to the hypothesis

## Limitations (if confounding variables are clearly identified by your group)

---

# References

---

- [Clean your data with R. R programming for beginners](https://www.youtube.com/watch?v=sV5lwAJ7vnQ&t=2s&ab_channel=RProgramming101)
- [Intro to Confidence Intervals via Proportions](https://www.youtube.com/watch?v=A6_W8qY8zJo&list=PLkIselvEzpM4SHQojH116fYAQJLaN_4Xo&ab_channel=OpenIntroOrg)
- [Hypothesis Testing Fundamentals](https://www.youtube.com/watch?v=NVbPE1_Cbx8&list=PLkIselvEzpM4SHQojH116fYAQJLaN_4Xo&ab_channel=OpenIntroOrg)
- [Inference for Estimators Other Than the Mean](https://www.youtube.com/watch?v=PUMBNtVKr_g&list=PLkIselvEzpM4SHQojH116fYAQJLaN_4Xo&ab_channel=OpenIntroOrg)
- [Why do we so often use 0.05 for hypothesis testing?](https://www.openintro.org/book/stat/why05/)
- [5 1A t distribution](https://www.youtube.com/watch?v=uVEj2uBJfq0&list=PLkIselvEzpM5G3IO1tzQ-DUThsJKQzQCD&ab_channel=Mine%C3%87etinkaya-Rundel)
- [5 1B Inference for a mean](https://www.youtube.com/watch?v=RYVIGj1l4xs&list=PLkIselvEzpM5G3IO1tzQ-DUThsJKQzQCD&ab_channel=Mine%C3%87etinkaya-Rundel)
- [5 2 Inference for paired data](https://www.youtube.com/watch?v=K0QZ9_4w0HU&list=PLkIselvEzpM5G3IO1tzQ-DUThsJKQzQCD&ab_channel=Mine%C3%87etinkaya-Rundel)
- [5 3 Difference of two independent means](https://www.youtube.com/watch?v=emZ24asR2F4&list=PLkIselvEzpM5G3IO1tzQ-DUThsJKQzQCD&ab_channel=Mine%C3%87etinkaya-Rundel)
- [Writing in the sciences...: Lab Reports](https://dkit.ie.libguides.com/writinginthesciences/LabReports)
- [How to Write a Lab Report](https://www.slideshare.net/libhgtc/how-to-write-a-lab-report-45656386)
- [Writing a Laboratory Report original (2016)](https://www.discoveringstatistics.com/docs/writinglabreports.pdf)
- [DPLYR Tutorial: Data Manipulation](https://www.listendata.com/2016/08/dplyr-tutorial.html)
- [How to Test for Normality in R](https://www.statology.org/test-for-normality-in-r/)
- [7 Types of Statistical Analysis: Definition and Explanation](https://www.analyticssteps.com/blogs/7-types-statistical-analysis-definition-explanation)