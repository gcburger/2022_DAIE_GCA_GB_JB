---
title: "Descriptive & Inferential Analysis of a Jungian Sandplay VR Project"
subtitle: "Normality testing of patient treatment"
author: "Gareth Burger &amp; James Bunt"
date: "`r format(Sys.time(), '%a, %d %B %y at %X')`"
fontsize: "10pt"
output: 
  html_document:
    toc: true
    toc_title: "Table Of Contents"
    toc_float: true
    toc_depth: 3
    fig_caption: false
    lof: true
    number_sections: true
    code_folding: hide
    theme: paper
---

```{r setup and library load, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
cat('\014')
```

**WIP**\
*We can rename this README or make the main R Notebook file a completely new file if needed*\
*2-2.5 pages of text needed, not more than 1200 words excluding plots and tables*\

# Abstract
*NB to be succinct and clear here*

## Aim and rationale

## Participants and setting

## Experiment design

## Results gathering

## Major findings

## Findings/implications


# Introduction

## Topic and context

## Rationale

*2. Formulate a single hypothesis test to be used to compare the effectiveness of the approaches used during the experiment.*\

## Hypothesis
We always have the null and the alternate hypothesis.
The null says no, the experiment didn't make any difference.
Give them animated models - didn't make any difference.
Male or Female, didn't make any difference.
Null = no effect

Alternate - something has happened here that is statistically significant
Though the probability of seeing a difference between pre and post is actually very low
p-value and t test
when p-value is below 0.05 - what you're saying is: I got a sample mean before of x, I got a sample mean of afterwards of x+2
difference is 2 (2/10 e.g.)
p-value below 0.05 means there's only a 5% that the null hypothesis can still be true given that you see these results
5% probability that the null hypothesis is true given that we are seeing the difference in values (of means)
if p-value is so low, and you're seeing the difference in values, and the null hypothesis is true, that's encouraging you to reject the null hypothesis - i.e. < 5% is the probability that the differences in means exist and that the null hypothesis is true
therefore p-value of <0.05 means reject the null hypothesis i.e something is indeed happening

For the CA we have to state what we think is the null (no effect) hypothesis and what the alternate hypothesis is

If it is quite unlikely to obtain results as in the actual data, we should decide to reject the null hypothesis in favour of the alternative

1. start with a null hypothesis (H0) (that represents no effect/the status quo)
2. state the alternative hypothesis (Ha) (the represents our research question)
3. Conduct a hypothesis test under the assumption that the null hypothesis is true, using p-value test which tells us the probability that this has occurred by accident is very low is p-value is < 0.05 i.e. reject null hypothesis - alternative hypothesis is true
so again p-value <0.05 means that there's only a 5% chance that we would be observing the difference between before and after means if the null hypothesis was true. So because the probability is really low, we have to reject the null hypothesis meaning its not true

If the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, we must stick with the null hypothesis. i.e. if p-value is >= 0.05, null hypothesis is true

- one null and one alternative hypothesis
- descriptive statistics - plots
- test for normality
- an abstract
- some conclusions, based on p-value reject or accepting null hypothesis

e.g.
mean before is 0.6
mean after is 0.7
the difference between the two means should not be zero, therefore there must be some effect
so that could be our alternate hypothesis
null is that no effect happened

only use student t test



# Method

## Participants

## Design

## Materials

## Procedure

### Load Data
```{r Load Data, echo=TRUE}
# load data from csv
file_name = "./data/daie_ca3_data_13.csv"
study_data <- read.csv(file_name)
```

*1. Determine whether the data provided are appropriate for the test(s) available and whether any data cleaning is required.*\

### Inspect Data Structure
```{r Inspect Head, Tail & Structure, echo=TRUE}
# show data structure
str(study_data)

# show first N
head(study_data, 10)

# show last N
tail(study_data, 10)

# show a paged table containing all the data
rmarkdown::paged_table(study_data)
```

### Clean Data
if there's an error in a row, we can elimate/ignore the row by filtering and exclude it from the data
comment on it at the end - a number of records were removed because they were considered to be in error

```{r}
# install.packages("tidyverse")
# install.packages("dplyr")

# load and attach tidyverse and dplyr packages
library(tidyverse)
library(dplyr)

View(study_data)

# variable types
glimpse(study_data)
class(study_data$post_trial_cpss)

# find distinct data values for columns
unique(study_data$gender) # incorrect spelling of value "mal", should be "Male"
unique(study_data$test_group) # value of "" is present, means missing data

# select variables (selects all valid data - see count is 147 row i.e. 3 rows have invalid/missing data)
study_data %>%
  select(gender, test_group, ends_with("cpss")) %>%
  filter(gender %in% c("Male", "Female") 
         & test_group %in% c("Static", "Control", "Animated") 
         & post_trial_cpss > 0, post_trial_cpss < 10)

# identify missing data
#mean(study_data$pre_trial_cpss, na.rm = TRUE) # remove not available observations from pre_trial_cpss variable
mean(study_data$pre_trial_cpss) #6.0618
mean(study_data$post_trial_cpss) #5.4154
mean(study_data$pre_trial_or) #6.072133
mean(study_data$post_trial_or) #5.3748
# all means were able to be calculated, thus there's no missing data in those columns

# filter observations of variables that have missing values (does not identify the 1 line with missing data, unsure why yet)
study_data %>%
  select(gender, test_group, pre_trial_cpss, post_trial_cpss, pre_trial_or, post_trial_or) %>%
  filter(!complete.cases(.)) # complete.cases not picking up row 42 '' test_group

# check for duplicates (no dupes)
study_data %>% distinct() # 150 rows returned, so no duplicates
duplicated(study_data) # all logical vector values are FALSE i.e. no duplicates

# continue here...
```

### Mean and Standard Deviation
```{r Mean & Median, echo=TRUE}
pre_trial_cpss_mean <- mean(study_data$pre_trial_cpss)
pre_trial_cpss_std <- sd(study_data$pre_trial_cpss)

post_trial_cpss_mean <- mean(study_data$post_trial_cpss)
post_trial_cpss_std <- sd(study_data$post_trial_cpss)

pre_trial_or_mean <- mean(study_data$pre_trial_or)
pre_trial_or_std <- sd(study_data$pre_trial_or)

post_trial_or_mean <- mean(study_data$post_trial_or)
post_trial_or_std <- sd(study_data$post_trial_or)
```

pre_trial_cpss: M = `r round(pre_trial_cpss_mean, 2)`, SD = `r round(pre_trial_cpss_std, 2)`

post_trial_cpss: M = `r round(post_trial_cpss_mean, 2)`, SD = `r round(post_trial_cpss_std, 2)`

pre_trial_or: M = `r round(pre_trial_or_mean, 2)`, SD = `r round(pre_trial_or_std, 2)`

post_trial_or: M = `r round(post_trial_or_mean, 2)`, SD = `r round(post_trial_or_std, 2)`

### Data Summary
A summary of the data is shown below:

```{r Summary, echo=TRUE}
summary(study_data)
```

*3. Determine if the data meet the assumptions required by any statistical test.*\

### Three Tests for Normality
[How to Test for Normality in R](https://www.statology.org/test-for-normality-in-r/)

#### Method 1: Using Histogram / Density Plot
```{r Histogram & Density Plot - pre_trial_cpss, echo=TRUE}
# draw histogram for pre_trial_cpss
hist(study_data$pre_trial_cpss, main = "pre_trial_cpss", xlab = "Measured Score", ylab = "Frequency", breaks = 6)
```

```{r Histogram & Density Plot - post_trial_cpss, echo=TRUE}
# draw histogram for post_trial_cpss
hist(study_data$post_trial_cpss, main = "post_trial_cpss", xlab = "Measured Score", ylab = "Frequency", breaks = 6)
```

```{r Histogram & Density Plot - pre_trial_or, echo=TRUE}
# draw histogram for pre_trial_or
hist(study_data$pre_trial_or, main = "pre_trial_or", xlab = "Measured Score", ylab = "Frequency", breaks = 6)
```

```{r Histogram & Density Plot - post_trial_or, echo=TRUE}
# draw histogram for post_trial_or
hist(study_data$post_trial_or, main = "post_trial_or", xlab = "Measured Score", ylab = "Frequency", breaks = 7)
```

#### Method 2: Using QQ Plot (Version 1 - using in-built qqnorm())
*visual inspection test*\
*samples are close to the qq line so gives a good indication that the data is normally distributed*\
*though they don't all fall exactly on the line so we'll do the next test to further investigate*\
```{r QQ Plot - pre_trial_cpss, echo=TRUE}
# perform qqnorm test on pre_trial_cpss
qqnorm(study_data$pre_trial_cpss, pch = 2, frame = FALSE)
qqline(study_data$pre_trial_cpss, col = "darkorchid", lwd = 1)
```

```{r QQ Plot - post_trial_cpss, echo=TRUE}
# perform qqnorm test on post_trial_cpss
qqnorm(study_data$post_trial_cpss, pch = 2, frame = FALSE)
qqline(study_data$post_trial_cpss, col = "darkorchid", lwd = 1)
```

```{r QQ Plot - pre_trial_or, echo=TRUE}
# perform qqnorm test on pre_trial_or
qqnorm(study_data$pre_trial_or, pch = 2, frame = FALSE)
qqline(study_data$pre_trial_or, col = "darkorchid", lwd = 1)
```

```{r QQ Plot - post_trial_or, echo=TRUE}
# perform qqnorm test on post_trial_or
qqnorm(study_data$post_trial_or, pch = 2, frame = FALSE)
qqline(study_data$post_trial_or, col = "darkorchid", lwd = 1)
```

#### Method 3: Statistical Test: Shapiro-Wilk
*the threshold for normality is 0.05*\
*if the p-value is above the threshold then we can accept the data to be normal*\
*if the p-value is close to the boundary, we want to test via a fourth method*\
```{r Shapiro-Wilk - pre_trial_cpss, echo=TRUE}
# perform shapiro-wilk test on pre_trial_cpss
pre_trial_cpss_sw <- shapiro.test(study_data$pre_trial_cpss)
pre_trial_cpss_sw
```
A `r pre_trial_cpss_sw$method` was conducted on the pre_trial_cpss data.\
From the output obtained we can assume normality as the p-value (p=`r round(pre_trial_cpss_sw$p.value, 4)`) is greater than 0.05.

```{r Shapiro-Wilk - post_trial_cpss, echo=TRUE}
# perform shapiro-wilk test on post_trial_cpss
post_trial_cpss_sw <- shapiro.test(study_data$post_trial_cpss)
post_trial_cpss_sw
```
A `r post_trial_cpss_sw$method` was conducted on the post_trial_cpss data.\
*data still needs to be cleaned*\
From the output obtained we can not assume normality as the p-value (p=`r format.pval(post_trial_cpss_sw$p.value, 5, eps = 0.001)`) is less than 0.05.

```{r Shapiro-Wilk - pre_trial_or, echo=TRUE}
# perform shapiro-wilk test on pre_trial_or
pre_trial_or_sw <- shapiro.test(study_data$pre_trial_or)
pre_trial_or_sw
```
A `r pre_trial_or_sw$method` was conducted on the pre_trial_or data.\
From the output obtained we can assume normality as the p-value (p=`r round(pre_trial_or_sw$p.value, 4)`) is greater than 0.05.

```{r Shapiro-Wilk - post_trial_or, echo=TRUE}
# perform shapiro-wilk test on post_trial_or
post_trial_or_sw <- shapiro.test(study_data$post_trial_or)
post_trial_or_sw
```
A `r post_trial_or_sw$method` was conducted on the post_trial_or data.\
From the output obtained we can assume normality as the p-value (p=`r round(post_trial_or_sw$p.value, 4)`) is greater than 0.05.


# Results

*4. Provide descriptive statistics (graphs and tables) for any assumptions made.*\

## Descriptive statistics
*plots - box, bar, scatter, qq plots*

## Inferential statistics
*the inference that we are doing on our data requires that the data is normally distributed*\

*6. Determine the 95% confidence interval for the population mean of each group, and the 95% confidence interval for the difference between the means of any two groups for a variable of your choice.*\

95% confidence interval = point estimate +- 1.96 * standard error

SE = sqrt( p(1-p)/n )  - slides 19-20 of chapter 5

p = point estimate +/- 1.96 * SE
  = PE +/- ***
We are 95% confident that [PE + x, PE - x] of all animated group patients, PTSD therapy helped them


*7. Determine the degree of correlation between any explanatory and response variable of your choice.*\

*do student t test - see diamond quality video*

## Statistical tests
[7 Types of Statistical Analysis: Definition and Explanation](https://www.analyticssteps.com/blogs/7-types-statistical-analysis-definition-explanation)

## Magnitude and direction of results


# Discussion

*5. Analyse the data to provide the hypothesis testing conclusion.*\

## Outline findings and relation to the hypothesis

## Limitations (if confounding variables are clearly identified by your group)


# References
- [Clean your data with R. R programming for beginners](https://www.youtube.com/watch?v=sV5lwAJ7vnQ&t=2s&ab_channel=RProgramming101)
- [Foundations for Inference: Point Estimates](https://www.youtube.com/watch?v=oLW_uzkPZGA&list=PLkIselvEzpM4SHQojH116fYAQJLaN_4Xo&ab_channel=OpenIntroOrg)
- [Intro to Confidence Intervals via Proportions](https://www.youtube.com/watch?v=A6_W8qY8zJo&list=PLkIselvEzpM4SHQojH116fYAQJLaN_4Xo&ab_channel=OpenIntroOrg)
- [Hypothesis Testing Fundamentals](https://www.youtube.com/watch?v=NVbPE1_Cbx8&list=PLkIselvEzpM4SHQojH116fYAQJLaN_4Xo&ab_channel=OpenIntroOrg)
- [Inference for Estimators Other Than the Mean](https://www.youtube.com/watch?v=PUMBNtVKr_g&list=PLkIselvEzpM4SHQojH116fYAQJLaN_4Xo&ab_channel=OpenIntroOrg)
- [Why do we so often use 0.05 for hypothesis testing?](https://www.openintro.org/book/stat/why05/)
- [5 1A t distribution](https://www.youtube.com/watch?v=uVEj2uBJfq0&list=PLkIselvEzpM5G3IO1tzQ-DUThsJKQzQCD&ab_channel=Mine%C3%87etinkaya-Rundel)
- [5 1B Inference for a mean](https://www.youtube.com/watch?v=RYVIGj1l4xs&list=PLkIselvEzpM5G3IO1tzQ-DUThsJKQzQCD&ab_channel=Mine%C3%87etinkaya-Rundel)
- [5 2 Inference for paired data](https://www.youtube.com/watch?v=K0QZ9_4w0HU&list=PLkIselvEzpM5G3IO1tzQ-DUThsJKQzQCD&ab_channel=Mine%C3%87etinkaya-Rundel)
- [5 3 Difference of two independent means](https://www.youtube.com/watch?v=emZ24asR2F4&list=PLkIselvEzpM5G3IO1tzQ-DUThsJKQzQCD&ab_channel=Mine%C3%87etinkaya-Rundel)
- [Writing in the sciences...: Lab Reports](https://dkit.ie.libguides.com/writinginthesciences/LabReports)
- [How to Write a Lab Report](https://www.slideshare.net/libhgtc/how-to-write-a-lab-report-45656386)
- [Writing a Laboratory Report original (2016)](https://www.discoveringstatistics.com/docs/writinglabreports.pdf)
- [DPLYR Tutorial: Data Manipulation](https://www.listendata.com/2016/08/dplyr-tutorial.html)
- [How to Test for Normality in R](https://www.statology.org/test-for-normality-in-r/)
- [7 Types of Statistical Analysis: Definition and Explanation](https://www.analyticssteps.com/blogs/7-types-statistical-analysis-definition-explanation)